{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9307fc8b",
   "metadata": {},
   "source": [
    "# Fake currency detection using ResNet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "750e40c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all necessary modules\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array \n",
    "from tensorflow.keras.layers import Dense,Activation,Flatten,Dropout\n",
    "from tensorflow.keras.models import Sequential,Model,load_model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06b9b65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define height and width of the image\n",
    "height=300\n",
    "width=300\n",
    "\n",
    "#create a ResNet50 model instance without the top layer as we will add our own top layer\n",
    "base_model=ResNet50(weights='imagenet',include_top=False,input_shape=(height,width,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2312366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2774 images belonging to 2 classes.\n",
      "Found 592 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#define directory containing training and validation data\n",
    "train_dir=\"dataset/training\"\n",
    "validation_dir=\"dataset/validation\"\n",
    "\n",
    "#number of batches the data has to be divided into\n",
    "batch_size=8\n",
    "\n",
    "#create datagen and generator to load the data from training directory\n",
    "train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input,rotation_range=90,horizontal_flip=True,vertical_flip=True)\n",
    "train_generator=train_datagen.flow_from_directory(train_dir,target_size=(height,width),batch_size=batch_size)\n",
    "\n",
    "#create datagen and generator to load the data from validation directory\n",
    "validation_datagen=ImageDataGenerator(preprocessing_function=preprocess_input,rotation_range=90,horizontal_flip=True,vertical_flip=True)\n",
    "validation_generator=validation_datagen.flow_from_directory(validation_dir,target_size=(height,width),batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3ca0b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_finetune_model(base_model,dropout,fc_layers,num_classes):\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable=False\n",
    "\n",
    "    x=base_model.output\n",
    "    x=Flatten()(x)\n",
    "    for fc in fc_layers:\n",
    "        x=Dense(fc,activation='relu')(x)\n",
    "        x=Dropout(dropout)(x)\n",
    "    \n",
    "    predictions=Dense(num_classes,activation='softmax')(x)\n",
    "\n",
    "    finetune_model=Model(inputs=base_model.input,outputs=predictions) \n",
    "    \n",
    "    return finetune_model\n",
    "\n",
    "class_list=['Real','Fake'] #the labels of our data\n",
    "FC_Layers=[1024,1024]\n",
    "dropout=0.5\n",
    "\n",
    "finetune_model=build_finetune_model(base_model,dropout=dropout,fc_layers=FC_Layers,num_classes=len(class_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1457ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=20\n",
    "num_train_images=2774"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25909d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PRATYAOY SARKAR\\FinalYrProject\\myenv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4954 - loss: 21954668078825472.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PRATYAOY SARKAR\\FinalYrProject\\myenv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from None to 0.75000, saving model to Final_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m796s\u001b[0m 2s/step - accuracy: 0.5011 - loss: 45607269873745920.0000 - val_accuracy: 0.7500 - val_loss: 415.2369\n",
      "Epoch 2/20\n",
      "\u001b[1m  1/346\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17:38\u001b[0m 3s/step - accuracy: 0.2500 - loss: 1278.3269"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PRATYAOY SARKAR\\FinalYrProject\\myenv\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.75000\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.2500 - loss: 1278.3269 - val_accuracy: 0.3750 - val_loss: 1058.2571\n",
      "Epoch 3/20\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.4973 - loss: 4000011255808.0000\n",
      "Epoch 3: val_accuracy did not improve from 0.75000\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2624s\u001b[0m 8s/step - accuracy: 0.4906 - loss: 1232771743744.0000 - val_accuracy: 0.5000 - val_loss: 0.6944\n",
      "Epoch 4/20\n",
      "\u001b[1m  1/346\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16:10\u001b[0m 3s/step - accuracy: 0.3750 - loss: 0.7071\n",
      "Epoch 4: val_accuracy did not improve from 0.75000\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.3750 - loss: 0.7071 - val_accuracy: 0.2500 - val_loss: 0.7193\n",
      "Epoch 5/20\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4952 - loss: 4599066.0000\n",
      "Epoch 5: val_accuracy did not improve from 0.75000\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m746s\u001b[0m 2s/step - accuracy: 0.4881 - loss: 50774976.0000 - val_accuracy: 0.6250 - val_loss: 0.6695\n",
      "Epoch 6/20\n",
      "\u001b[1m  1/346\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:16\u001b[0m 2s/step - accuracy: 0.1250 - loss: 0.8290\n",
      "Epoch 6: val_accuracy did not improve from 0.75000\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.1250 - loss: 0.8290 - val_accuracy: 0.3750 - val_loss: 0.7329\n",
      "Epoch 7/20\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4845 - loss: 56917076.0000\n",
      "Epoch 7: val_accuracy did not improve from 0.75000\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m738s\u001b[0m 2s/step - accuracy: 0.4913 - loss: 85783592.0000 - val_accuracy: 0.6250 - val_loss: 0.6876\n",
      "Epoch 8/20\n",
      "\u001b[1m  1/346\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16:25\u001b[0m 3s/step - accuracy: 0.5000 - loss: 0.7056\n",
      "Epoch 8: val_accuracy did not improve from 0.75000\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5000 - loss: 0.7056 - val_accuracy: 0.1250 - val_loss: 0.7112\n",
      "Epoch 9/20\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5023 - loss: 678032128.0000\n",
      "Epoch 9: val_accuracy did not improve from 0.75000\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m775s\u001b[0m 2s/step - accuracy: 0.4975 - loss: 1606140800.0000 - val_accuracy: 0.7500 - val_loss: 0.6090\n",
      "Epoch 10/20\n",
      "\u001b[1m  1/346\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:38\u001b[0m 2s/step - accuracy: 0.3750 - loss: 0.7768\n",
      "Epoch 10: val_accuracy did not improve from 0.75000\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.3750 - loss: 0.7768 - val_accuracy: 0.3750 - val_loss: 0.6983\n",
      "Epoch 11/20\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4809 - loss: 555.2064\n",
      "Epoch 11: val_accuracy did not improve from 0.75000\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m780s\u001b[0m 2s/step - accuracy: 0.4881 - loss: 210.9032 - val_accuracy: 0.7500 - val_loss: 0.6897\n",
      "Epoch 12/20\n",
      "\u001b[1m  1/346\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:28\u001b[0m 2s/step - accuracy: 0.1250 - loss: 0.6984\n",
      "Epoch 12: val_accuracy did not improve from 0.75000\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.1250 - loss: 0.6984 - val_accuracy: 0.3750 - val_loss: 0.6949\n",
      "Epoch 13/20\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5141 - loss: 1.1505\n",
      "Epoch 13: val_accuracy did not improve from 0.75000\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m907s\u001b[0m 3s/step - accuracy: 0.4967 - loss: 1.8255 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 14/20\n",
      "\u001b[1m  1/346\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:03\u001b[0m 2s/step - accuracy: 0.3750 - loss: 0.6949\n",
      "Epoch 14: val_accuracy did not improve from 0.75000\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.3750 - loss: 0.6949 - val_accuracy: 0.3750 - val_loss: 0.6949\n",
      "Epoch 15/20\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.4961 - loss: 88225.1875\n",
      "Epoch 15: val_accuracy did not improve from 0.75000\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1058s\u001b[0m 3s/step - accuracy: 0.5007 - loss: 380091.3125 - val_accuracy: 0.3750 - val_loss: 519.3531\n",
      "Epoch 16/20\n",
      "\u001b[1m  1/346\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:08\u001b[0m 2s/step - accuracy: 0.5000 - loss: 398.8329\n",
      "Epoch 16: val_accuracy did not improve from 0.75000\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5000 - loss: 398.8329 - val_accuracy: 0.5000 - val_loss: 47.9606\n",
      "Epoch 17/20\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5006 - loss: 3.2237\n",
      "Epoch 17: val_accuracy did not improve from 0.75000\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m756s\u001b[0m 2s/step - accuracy: 0.4949 - loss: 1.2924 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 18/20\n",
      "\u001b[1m  1/346\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:52\u001b[0m 2s/step - accuracy: 0.6250 - loss: 0.6925\n",
      "Epoch 18: val_accuracy did not improve from 0.75000\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6250 - loss: 0.6925 - val_accuracy: 0.6250 - val_loss: 0.6925\n",
      "Epoch 19/20\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4765 - loss: 112.6956\n",
      "Epoch 19: val_accuracy did not improve from 0.75000\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m765s\u001b[0m 2s/step - accuracy: 0.4870 - loss: 79.2048 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 20/20\n",
      "\u001b[1m  1/346\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:30\u001b[0m 2s/step - accuracy: 0.6250 - loss: 0.6930\n",
      "Epoch 20: val_accuracy did not improve from 0.75000\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6250 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6931\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The filename must end in `.weights.h5`. Received: filepath=Final_model.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m finetune_model.fit(train_generator,steps_per_epoch=num_train_images//batch_size,epochs=num_epochs,validation_data=validation_generator,validation_steps=\u001b[32m1\u001b[39m,callbacks=[checkpoint,early])\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m#save the model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mfinetune_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFinal_model.h5\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PRATYAOY SARKAR\\FinalYrProject\\myenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PRATYAOY SARKAR\\FinalYrProject\\myenv\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:227\u001b[39m, in \u001b[36msave_weights\u001b[39m\u001b[34m(model, filepath, overwrite, max_shard_size, **kwargs)\u001b[39m\n\u001b[32m    225\u001b[39m filepath_str = \u001b[38;5;28mstr\u001b[39m(filepath)\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_shard_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filepath_str.endswith(\u001b[33m\"\u001b[39m\u001b[33m.weights.h5\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    228\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe filename must end in `.weights.h5`. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    229\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    230\u001b[39m     )\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m max_shard_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filepath_str.endswith(\n\u001b[32m    232\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mweights.h5\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mweights.json\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    233\u001b[39m ):\n\u001b[32m    234\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    235\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe filename must end in `.weights.json` when `max_shard_size` is \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    236\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mspecified. Received: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    237\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: The filename must end in `.weights.h5`. Received: filepath=Final_model.h5"
     ]
    }
   ],
   "source": [
    "\n",
    "#checkpoint in case anything goes wrong\n",
    "checkpoint=ModelCheckpoint(\"Final_model.h5\",monitor='val_accuracy',verbose=1,save_best_only=True,save_weights_only=False,mode='auto',save_freq='epoch')\n",
    "early=EarlyStopping(monitor='val_accuracy',min_delta=0,patience=40,verbose=1,mode=\"auto\")\n",
    "\n",
    "#compile the model before using\n",
    "optimizer = optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
    "finetune_model.compile(loss=\"categorical_crossentropy\",optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "#train the model\n",
    "finetune_model.fit(train_generator,steps_per_epoch=num_train_images//batch_size,epochs=num_epochs,validation_data=validation_generator,validation_steps=1,callbacks=[checkpoint,early])\n",
    "\n",
    "#save the model\n",
    "finetune_model.save_weights(\"Final_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d96159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
